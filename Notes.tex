
%Prefacio
\include{Prefacio}

\title{Category Theory and \\ Computational Complexity}
\author{Marco Larrea \and Octavio Zapata}

\begin{document}
\maketitle

\section{Introduction}

\subsection{Computability}
Here some rudiments of the computability theory and complexity theory.

\subsubsection{Turing machines}\label{ap:1}

A Turing machine is a particular assembly and mode of operation of the following components: a finite set of symbols $S$ which contains element $\bot\in S$ called the ``blank" symbol; a subset $\Sigma\subseteq S\setminus \{\bot\}$ called the \emph{input alphabet}; a finite set of states $Q$ which contains an initial state $q_0\in Q$; a partial function $\delta : Q\times S\rightarrow Q\times S\times\{-1,0,1\}$ called the transition function.

Computation is performed by a read-write head on symbols over a tape divided into cells, each cell carries one symbol from $S$.  The tape is infinite to the right; its content is a sequence $\sigma = \sigma_0, \sigma_1,\dots$ where $\sigma_i\in \Sigma$. The head in position $p\in\mathbb{N}$ can read symbol $s_p$ and write another symbol in its place. The configuration of a Turing machine is a triple $\langle\sigma ; p; q\rangle$ where $q\in Q$.

At each step the machine computes $\delta(q,s_p) = (q^{\prime}, s^{\prime}, \Delta p)$, which determines its new configuration $\langle s_0,\dots,s_{p-1}, s^{\prime},s_{p+1},\dots; p+\Delta p; q^{\prime}\rangle$ after the transition. A Turing machine \emph{halts} whenever $\delta(q,s_p)$ is undefined, or $p+\Delta p < 0$. Otherwise, it may never stops.

Inputs and outputs are strings over $\Sigma$. Initially the tape is filled with $\sigma\in \Sigma^{\ast}$ and padded with blanks; the head is at the left end so the initial configuration of the machine is $\gamma_0 := \langle\sigma\bot\bot\dots ; 0; q_0\rangle$. If the machine eventually halts, the output is the string written on the tape. In general, a computation can be seen as a sequence of configurations \[\langle\sigma\bot\bot\dots ; 0; q_0\rangle\rightarrow\langle\sigma^{\prime} ; p; q\rangle\rightarrow\cdots\] which we will denote by $\gamma_0\vdash\gamma_1\vdash\cdots$.


Every Turing machine $M$ computes a partial function $\Phi_{M} : \Sigma^{\ast}\rightarrow \Sigma^{\ast}$. By definition, $\Phi_{M} (\sigma)$ is the output string for input $\sigma$. The value $\Phi_{M} (\sigma)$ is undefined if the computation never terminates.

A partial function $f :\Sigma^{\ast}\rightarrow \Sigma^{\ast}$ is \emph{computable} if there exists a Turing machine $M$ such that $\Phi_{M} = f$. In this case we say that $f$ is computed by $M$.

 A predicate is a property that can be true or false. Predicates whose domain of discourse is the set $\Sigma^{\ast}$ can be identified with languages $\{x : P(x)\}\subseteq \Sigma^{\ast}$ over $\Sigma$. Formally, a predicate is a function $P :\Sigma^{\ast}\rightarrow \{0,1\}$ which is said to be decidable if there exists a Turing machine that computes it.


A Turing machine $M$ works in time $T(n)$ if it performs at most $T(n)$ steps to computes $\Phi_{M} (\sigma)$ for any $\sigma\in \Sigma^{\ast}$ such that $|\sigma|=n$. Analogously, $M$ works in space $s(n)$ if $|\Phi_{M} (\sigma)|\leq s(n)$ for any $\sigma\in \Sigma^{\ast}$ such that $|\sigma|=n$.

A  nondeterministic Turing machine is a Turing machine which have a multivalued transition function, i.e. the function $\delta$ is not an injection.


 For some purpose it may be convenient to consider multitape Turing machines that have a finite number of tapes. Each tape has a head that can read and write symbols on it. However, two special tapes are distinguished: an input read-only tape, and an output write-only tape. The remaining tapes are called the work tapes. 


\subsubsection{Complexity classes}\label{ap:2}

Let $f$ and $g$ be two functions. For sufficiently large $n$, if $|f(n)|\leq k\cdot g(n)$ for some $k>0$, we write $f(n)\in O(g(n))$; if $f(n)\geq k\cdot g(n)$ for some $k>0$, we write $f(n)\in \Omega (g(n))$. If, particularly $f(n)\leq c\cdot n^k$ for some $c,k$ constants, we write $f(n)= \poly(n)$.

A function $F$ on $\Sigma^{\ast}$ is computable in polynomial time if there exists a Turing machine that computes it in time $T(n) =\poly(n)$, for every $\sigma\in \Sigma^{\ast}$ such that $|\sigma| = n$. If $F$ is a predicate, we say that it is decidable in polynomial time.

We define the complexity class $\P$ as the class of all functions computable in polynomial time, or all predicates decidable in polynomial time. Notice that $F\in\P$ implies $|F(x)| =\poly(|x|)$.

A function (predicate) $F$ on $\Sigma^{\ast}$ is computable (decidable) in polynomial space if there exists a Turing machine that computes $F$ and runs in space $s(n) =\poly(n)$, for every $\sigma\in \Sigma^{\ast}$ such that $|\sigma| = n$.

The class of all functions (predicates) computable (decidable) in polynomial space is called $\PSPACE$. Notice from the definitions that clearly $\P\subseteq\PSPACE$. 

Complexity class $\NP$ is defined as the class of predicates decidable in polynomial time by nondeterministic Turing machines. Notice that $\NP$ is defined only for predicates. The class $\coNP$ is defined as the class of predicates whose complements are in the $\NP$ class. 

Let $\Sigma_{0}^{\P} := \Pi_{0}^{\P} := \P$. For $i\geq 0$, define $\Sigma_{i+1}^{\P} := \NP^{\Sigma_{i}^{\P}}$ and $\Pi_{i+1}^{\P} :=\coNP^{\Pi_{i}^{\P}}$ where $\varA^{\varB}$ is the class of languages accepted by a Turing machine that computes languages in $\varA$, augmented by a particular machine that computes languages in $\varB$. Notice that  $\Sigma_{1}^{\P} = \NP$.

The polynomial hierarchy $\Sigma_{\ast}\P$ is defined as
\begin{equation*}
\Sigma_{\ast}\P\ \ :=\ \bigcup_{i\in\mathbb{N}} \Sigma_{i}^{\P}\ :=\ \bigcup_{i\in\mathbb{N}} \Pi_{i}^{\P}.
\end{equation*}


\begin{conj}
It follows from the definitions that
\begin{equation*}
%\text{L}\ \subseteq\ \text{NL}\ \subseteq\ 
\P \subseteq\ \{\NP, \coNP \}\ \subseteq\ \Sigma_{\ast}\P\ \subseteq\ \PSPACE.
\end{equation*}
\end{conj}

\subsection{Descriptive complexity}
Let $\L$ be a logic, $\C$ a complexity class and $\K$ a class of finite structures. We say that $\L$ captures $\C$ on $\K$ if for every vocabulary $\tau$ and every property $\mathcal{P}\in\K(\tau)$
\[\mathcal{P}\text{ is $\LL$-definable }\Leftrightarrow\ L(\mathcal{P})\in\C.\] This fact is denoted as $\L =_{} \C$. 


\subsection{First-order dependence}

A first-order dependence logic $\D$ is a class which consists of all $\D$-definable properties where $\D := (\FO + \mu.\bar{t})$ and $\mu.\bar{t}$ denotes that term $t_{|\bar{t}|}$ is functionally dependent on $t_{i}$ for all $i\leq |\bar{t}|$. The model class $\FO$ is as always defined as the class of models of all first-order sentences (i.e. $\FO:= \{S:(\exists\tau)(\exists\varphi\in L(\tau))\ S=\Mod(\varphi)\}$ where $L(\tau)$ is a first-order language of type $\tau$) and $\mu.\bar{t}$ is interpreted as a recursively generated tuple of terms which we naturally identify with the set $[|\bar{t}|] := \{1,2,\dots,|\bar{t}|\}$. $\D$ sentences are capable to characterise variable dependence and in general they are proven to be as expressive as the sentences of the second order existential $\SO\exists$ model class \cite{dep}. The intuitionistic dependence version $\ID$ has the same expressive power as full $\SO$ \cite{dep}. It is a fact that $\MID$-model checking is $\PSPACE$-complete \cite{dep} where $\MID$ is the intuitionistic implication fragment of the modal dependence logic $\MD$ which contains at least two modifiers. Hence, $(\FO + \mu.\bar{t}) = \NP, \ID = \Sigma_{\ast}\P$ and $\MID = \PSPACE$.  On the other hand, $\PSPACE = \IP = \QIP$ \cite{qip}, and so $\MID = \QIP$ which is the quantum version of the interactive polytime class $\IP$.

We shall try to cook up a purely algebraic definition for the class of structures $\MID$ and extend such algebraic logic in order to capture other quantum and classical complexity classes. 

\subsection{Ultraproduct}

In this section every vocabulary $\tau$ will be referred as a similarity type or simply as a type.

The model class $\FO$ is, as always, defined as the class of models of all first-order sentences, i.e. $\FO:= \{S:(\exists\tau)(\exists\varphi\in L(\tau))\ S=\Mod(\varphi)\}$ where $L(\tau)$ is a first-order language of type $\tau$.

Ehrenfeucht-Fra\"iss\'e games characterise the expressive power of logical languages \cite{ams}. Every Ehrenfeucht-Fra\"iss\'e game is an ultraproduct \cite{models}, a back-and-forth method for showing isomorphism between countably infinite structures, but only defined for finite structures in finite model theory. If $F$ is an ultrafilter (i.e. $F\subseteq 2^{\mathbb{N}}$ and $\forall X\subseteq\mathbb{N} (X\notin F \Leftrightarrow \mathbb{N}\setminus X\in F)$ holds) then the reduced product $\prod_{i}M_i / F$ is an ultraproduct of the sets $M_i$, $i\in I$. Recall that \[f\sim g \Leftrightarrow \{i\in I : f(i) = g(i)\}\in F\] for all infinite sequences $f,g\in\prod_i M_i$ and any index set $I$, is the relation which induces the equivalence classes that conform the ultraproduct \[\prod_{i}M_i / F = \{[f]:f\in\prod_i M_i\}.\] 

This mathematical tool (the ultraproduct) is widely important because of results such as the following, from which proof we will delayed for the moment.

\begin{lem}[$\L$o\'s Lemma]
If $F$ is an ultrafilter and $\varphi$ a first-order formula, then the ultraproduct of models of $\varphi$ indexed by any index set $I\in F$ is a model of $\varphi$, i.e. \[(\prod_i A_i / F , \alpha)\models\varphi\Leftrightarrow\{i\in I: (A_i, \alpha_i)\models\varphi\}\in F.\]
\end{lem}

\subsubsection{Ultrafilters}


%\subsection{Descriptive complexity}
%%
%%
%Recall that a partial function $f$ is said to be \emph{computable} if there is a Turing machine $M$ such that $f$ is computed by $M$ (cf. Definition \ref{df:7}). Let us consider two languages $\mathcal{A, B}$ over the alphabet $\Sigma$, and a family of functions $\F$ from $\Sigma^{\ast}$ to itself that is closed under composition. We say that $\mathcal{A}$ is \emph{reducible} to $\mathcal{B}$ \emph{under} $\F$, if there is a function $f\in\F$ such that for all $x\in\Sigma^{\ast}$ we have $f(x)\in B$ if and only if $x\in \mathcal{A}$. We denote this by $\mathcal{A}\leq_{\F} \mathcal{B}$. Then, we say that $\mathcal{A}\leq_f \mathcal{B}$ is a polynomial time reduction from $\mathcal{A}$ to $\mathcal{B}$ if $f$ is computable in polynomial time, and we write $\mathcal{A}\leq_{\p} \mathcal{B}$ to denote this. If $f$ is definable by a first-order formula, then say that $\mathcal{A}\leq_{\FO} \mathcal{B}$ is a first-order reduction.
%
%Now, let $\S\subseteq 2^{\Sigma^{\ast}}$ be a set of languages over the alphabet $\Sigma$, and $\F$ a family of functions from $\Sigma^{\ast}$ to itself . We say that $\S$ is \emph{closed under} $\F$-reductions if for each $\mathcal{S}\in\S$ there is a function $f\in\F$ such that for all $\mathcal{L}\subseteq\Sigma^{\ast}$ \[\mathcal{L}\leq_{f}\mathcal{S}\ \text{ implies }\ \mathcal{L}\in\S.\]
%
%We say that a language $\mathcal{L}\subseteq\Sigma^{\ast}$ is \emph{hard} for $\S$ if every language $\mathcal{S}\in\S$ reduces to $\mathcal{L}$. That is, for each $\mathcal{S}\in\S$ there is a function $f\in\F$ such that $\mathcal{S}\leq_{f}\mathcal{L}$. Also, we say that a language $\mathcal{L}\subseteq\Sigma^{\ast}$ is \emph{complete} for $\S$ if $\mathcal{L}$ is hard for $\S$ and $\mathcal{L}\in\S$.
%
%Then, let us notice that computational problems may be encoded as binary strings $x\in\{0,1\}^{\ast}$, decision problems as languages $\mathcal{L}\subseteq\{0,1\}^{\ast}$, and complexity clases as sets $\C\subseteq 2^{\{0,1\}^{\ast}}$ of languages. Equivalently, each formula $\varphi\in\LL[\tau]$ express a computational problem, each class of structures $\mathcal{P}\subseteq\Str[\tau]$ describes a decision problem, and each logic $\LL$ embraces a complexity class. 
%
%We will write $\LL = \C$ to denote that the logic $\LL$ embraces the complexity class $\C$, that is, when every \emph{instance} of $\C$ can be described by an $\LL$-definable property. By an instance of a complexity class $\C$ we mean any language $\mathcal{L}\in\C$ that is complete for $\C$ via first-order reductions. 
%
%The general procedure to prove that $\LL = \C$ will be the following:
%\begin{itemize}
%\item[1.] For each $\varphi\in\LL[\tau]$, produce an algorithm in $\C$ that decides the set \[\Mod[\varphi] = \{A:A\models\varphi\}.\]
%\item[2.] Produce a language $\mathcal{L}$ complete for $\C$ via first-order reductions.
%\item[3.] Show that $\LL$ is closed under first-order reductions.
%\item[4.] Describe a $\LL$-definable property $\mathcal{P}$ such that $\mathcal{L} = \mathcal{L}(\mathcal{P})$. 
%\end{itemize}

\section{Categorical Semantics of the Lambda Calculus}


The $\lambda-$calculus is an abstraction of the theory of functions,
in the same way group theory is an abstraction of the theory of
symmetries. There are two basic operation on function we would like to
formalize, \emph{application} and \emph{abstraction}.

Application refers to the operation performed by a function on a given
term or expression. For example, if $double$ is the function that
multiplies by two, then for any given natural number $n$, we can apply
$double$ to $n$ to form the new natural number $double(n) = 2n$. Note
that in order to be consistent one should define the type of
arguments a function can take, for instance, it makes no sense to
apply $double$ to a string ``$string$'' of characters. 

Abstraction is the operation of introducing new functions. Given a
term $t$ which (possibly) depends on a variable $x$, we can form a
new function by abstracting the variable $x$ from the term $t$ in such a
way that the application of this function on a term $u$ is given by
substituting in $t$ the variable $x$ by $u$. So for example, if we
have the term $t = x * 2$ which depends on $x$, we form the function
$\lambda x.t$ which extensionally is the same as the function $double$
from above, that is $\lambda x.t(n) = double(n) = 2n$ for all natural
number $n$.

The \emph{simply-typed lambda calculus} is a form of type theory that
interpretes the $\lambda$-calculus. Types are used in order to improve
the consistency of the originally untyped theory.

The first step to define the simply-typed lambda calculus is to fix a
set $\beta$ whose elements we name \emph{basic types} or \emph{atomic types}. We
express the fact that an object is a \emph{type} by the judgment:
\[
A \ type
\]

We want every element of $\beta$ to be a type, for this we introduce an
\emph{axiom} which is a special kind of \emph{deduction rule} for which
there are no assumptions. So for each $A \in \beta$ we have the rule:

\begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$A \ type$}
\end{prooftree}
which is read ``$A$ is a type''. We'll also want to have a special
type with only one term which we shall name the \emph{unit type}:

\begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$1 \ type$}
\end{prooftree}

There are two introduction rules for types, these rules tell us how to construct new types from old ones. There is the introduction rule for \emph{product types}:

\begin{prooftree}
      \AxiomC{$A \ type$}
      \AxiomC{$B \ type$}
      \BinaryInfC{$A \times B \ type$}
\end{prooftree}
and the introduction rule for \emph{function types}:

\begin{prooftree}
      \AxiomC{$A \ type$}
      \AxiomC{$B \ type$}
      \BinaryInfC{$A \rightarrow B \ type$}
\end{prooftree}

Therefore the set of all types of the simply-typed lambda calculus is recursively generated from the set of basic types by applying the introduction rules of products and functions. 

Now the set of types is defined we would like to define in a similar way the set of terms. As before we fix a set of \emph{constant terms} or just \emph{constants}. We also asume there are countable many variables (or as many as we might need), we'll name the variables $x, y, z, \dots$. Just as types we will recursively generate the set of terms as follows:
\[
t := [variables] \ | \ [constants] \ | \  * \ | \ <t , t'> \ | \ \pi_1 t \ | \ \pi_2 t \ | \ t(t') \ | \ \lambda x.t
\]
A term of the form $t(t')$ is called an \emph{application} and one of the form $\lambda x.t$ is called a \emph{lambda abstraction}.

There are two ways a variable $x$ can appear in a given term $t$. We say that $x$ is \emph{bound} in $t$ if it appears in the scope of a lambda abstraction, i.e. if inside of $t$ there is a substring of the form $\lambda x.t'$ for some $t'$. \emph{Free} variables are those that are not bound.

A very important syntactic operation of terms is \emph{substitution}. Given a term $t$ (such that a variable $x$ may ocurre freely in it), for any term $u$, the new term
\[
t[u/x]
\]
is obtained from $t$ by substituting the free occurrences of the variable $x$ by $u$. For example, consider the term:
\[
t = <\lambda x.<x, y> , z>
\]
In $t$ we have that the variables $y$ and $z$ are free while $x$ is bound. Let $u = <a , \lambda w.w>$, we can substitute in $t$ the variable $y$ for $u$ to form the next term:
\[
t[u/y] = <\lambda x.<x, <a, \lambda w.w>> , z>
\]
If we try to substitute the variable $x$ for $u$ we would obtain the term $t$ again since $x$ is bound, i.e. $t[u/x] = t$.

A \emph{context} is a finite sequence of typed variables, that is, if $x_1, x_2, \dots , x_n$ are distinct variables and $A_1, A_2, \dots , A_n$ are types, the sequence 
\[
x_1 : A_1 , x_2 : A_2 , \dots , x_n : A_n
\]  
is a context, the empty sequence is a valid context. We denote contexts with capital greek letters $\Delta, \Gamma, \dots$

A \emph{typing judgment} is of the form:
\[
\Gamma \vdash t:A
\]
where $\Gamma$ is a context, $t$ a term and $A$ a type. We read the above judgement as ``In context $\Gamma$ the term $t$ is of type $A$''. Intuitively what we mean by this judgement is that the free variables of $t$ must ocurre in $\Gamma$.

To form new typing judgements we need to follow some specified rules. We will now enunciate the rules of the simply-typed lambda calculus.
\begin{itemize}
  \item Each constant term has a unique determined type, i.e. for each constant $a$ there is a unique type $A$   such that for every context $\Gamma$ we have that:
    \begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$\Gamma \vdash a : A$}
    \end{prooftree}

    \item The type of a variable is determined by the context, i.e. if $x_i : A_i$ ocurre in a context $\Gamma$ we have that:
    \begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$\Gamma \vdash x_i : A_i$}
    \end{prooftree}

    \item The term $*$ has type $1$ in every context:
    \begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$\Gamma \vdash * : 1$}
    \end{prooftree}

    \item The context of a given judgement can be extended. This rule is known as \emph{weakening}:
    \begin{prooftree}
      \AxiomC{$\Gamma \vdash t : A$}
      \UnaryInfC{$\Gamma , \Delta \vdash t : A$}
    \end{prooftree}
    where the context $\Gamma , \Delta$ is given by the union $\Gamma \cup \Delta$.

    \item Rules for product types:
    \begin{center}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}  
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash u : A$}
          \AxiomC{$\Gamma \vdash t : B$}
          \BinaryInfC{$\Gamma \vdash <u, t> : A \times B$}
        \end{prooftree}
      \end{minipage}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash t : A \times B$}
          \UnaryInfC{$\Gamma \vdash \pi_1 t : A$}
        \end{prooftree}
      \end{minipage}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash t : A \times B$}
          \UnaryInfC{$\Gamma \vdash \pi_2 t : B$}
        \end{prooftree}
      \end{minipage}
    \end{center}
    
    \item Rules for function types:
    \begin{center}
      \vspace{0pt}  
      \begin{minipage}[t]{5cm}
        \vspace{0pt}  
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash t : A \rightarrow B$}
          \AxiomC{$\Gamma \vdash u : A$}
          \BinaryInfC{$\Gamma \vdash t(u) : B$}
        \end{prooftree}
      \end{minipage}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}
        \begin{prooftree}
          \AxiomC{$\Gamma , x : A \vdash t : B$}
          \UnaryInfC{$\Gamma \vdash \lambda x.t : A \rightarrow B$}
        \end{prooftree}
      \end{minipage}
    \end{center}
where $\Gamma , x : A$ is the context $\Gamma \cup \{x : A\}$.
\end{itemize}

Apart from the typing judgment there is another kind of syntactic judgement, the \emph{equality judgement}, this specifies when two terms of the same type (under the same context) are equal. It's written as follows:
\[
\Gamma \vdash t = u : A
\]
Equality must at least be an equivalence relation, so we have the following rules:
    \begin{center}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}  
        \begin{prooftree}
          \AxiomC{}
          \UnaryInfC{$\Gamma \vdash t  = t : A$}
        \end{prooftree}
      \end{minipage}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash t = u : A$}
          \UnaryInfC{$\Gamma \vdash u = t : A$}
        \end{prooftree}
      \end{minipage}
      \begin{minipage}[t]{5cm}
        \vspace{0pt}
        \begin{prooftree}
          \AxiomC{$\Gamma \vdash t = u : A$}
          \AxiomC{$\Gamma \vdash u = v : A$}
          \BinaryInfC{$\Gamma \vdash t = v : A$}
        \end{prooftree}
      \end{minipage}
    \end{center}

The equality judgement must behave well with the rules for typing judgements, this means that for each of the rules seen before, there is an appropriate coherence rule for equality judgement. For example, for the application rule of functions, we have the corresponding rule:
\begin{prooftree}
      \AxiomC{$\Gamma \vdash f = g : A \rightarrow B$}
      \AxiomC{$\Gamma \vdash u = v : A$}
      \BinaryInfC{$\Gamma \vdash f(u) = g(v) : B$}
\end{prooftree}
This is true for all the rules previously stated: weakening rule, product and function rules and unit rule.

Finally there are three important rules that are meant to formalize the important notions of function application and abstraction.
\begin{itemize}
\item The \emph{$\alpha$-conversion} rule formalizes the notion that bound variables in a given term can be interchanged without altering the meaning of the term:
\begin{prooftree}
  \AxiomC{$\Gamma , x : A \vdash t : B$}
  \RightLabel{(\emph{$\alpha$-conv})}
  \UnaryInfC{$\Gamma \vdash \lambda x.t = \lambda y.t[y/x] : A \rightarrow B$}
\end{prooftree}
where $y$ is a variable that does not ocurre freely in $t$.

\item The \emph{$\beta$-reduction} rules tells us that if we first abstract a variable $x$ from a term $t$ and then apply the resulting function to another term $u$, the result must be the same as syntactically substituting $u$ for $x$ in the original term $t$:
\begin{prooftree}
  \AxiomC{$\Gamma , x : A \vdash t : B$}
  \AxiomC{$\Gamma \vdash u : A$}
  \RightLabel{(\emph{$\beta$-redu})}
  \BinaryInfC{$\Gamma \vdash (\lambda x.t)(u) = t[u/x] : B$}
\end{prooftree}

\item The \emph{$\eta$-reduction} formalizes the notion of function extensionality, i.e. that two function that have the same output on each term are equal:

\begin{prooftree}
  \AxiomC{$\Gamma \vdash f : A \rightarrow B$}
  \RightLabel{(\emph{$\eta$-redu})}
  \UnaryInfC{$\Gamma \vdash \lambda x . f(x) = f : A \rightarrow B$}
\end{prooftree}
\end{itemize}

The above collection of data characterise the simply-typed lambda calculus, so let's summarize this in a definition.
\begin{defn}
A \emph{simply-typed lambda calculus} is given by a set of Basic Types and a set of Constants subject to the rules given above. 
\end{defn}

\nocite{*}
\bibliographystyle{alpha}
\bibliography{paper}

\end{document}
